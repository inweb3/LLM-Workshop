{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a virtual environment and install the required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "cat /etc/os-release\n",
    "nvcc -V\n",
    "cd ../personal_copilot\n",
    "python3.11 -m venv .copilot\n",
    "source .copilot/bin/activate\n",
    "pip install --upgrade pip setuptools wheel\n",
    "pip install torch torchvision torchaudio\n",
    "pip install packaging\n",
    "pip install flash-attn\n",
    "pip install -r training/requirements.txt\n",
    "pip install -r dateset_generation/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow `personal_copilot/README.md`. \n",
    "\n",
    "```shell\n",
    "export GH_ACCESS_TOKEN=xxxx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../dataset_generation\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python clone_hf_repos.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls hf_public_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could collate and push to hub.\n",
    "\n",
    "```shell\n",
    "python prepare_hf_dataset.py\n",
    "```\n",
    "\n",
    "but since this is a public dataset, we can also just download it from the hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "```shell\n",
    "python train.py \\\n",
    "    --model_name_or_path \"bigcode/starcoder2-7b\" \\\n",
    "    --lora_r 32 \\\n",
    "    --lora_alpha 64 \\\n",
    "    --lora_dropout 0.0 \\\n",
    "    --lora_target_modules \"c_proj,c_attn,q_attn,c_fc,c_proj\" \\\n",
    "    --use_nested_quant \\\n",
    "    --bnb_4bit_compute_dtype \"bfloat16\" \\\n",
    "    --use_flash_attn \\\n",
    "    --use_peft_lora \\\n",
    "    --use_4bit_quantization \\\n",
    "    --dataset_name \"smangrul/hug_stack\" \\\n",
    "    --dataset_text_field \"text\" \\\n",
    "    --max_seq_length 1024 \\\n",
    "    --fim_rate 0.5 \\\n",
    "    --fim_spm_rate 0.5 \\\n",
    "    --splits \"train\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --bf16 \\\n",
    "    --learning_rate 5e-4 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --max_steps 1000 \\\n",
    "    --warmup_steps 30 \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --evaluation_strategy \"steps\" \\\n",
    "    --eval_steps 50 \\\n",
    "    --save_steps 50 \\\n",
    "    --logging_steps 25 \\\n",
    "    --output_dir \"peft-lora-starcoder2-7b-personal-copilot-dual-3090-local\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training is interrupted, we can resume it by adding `--resume_from_checkpoint \"path/to/checkpoint\"`.\n",
    "\n",
    "```shell\n",
    "    python train.py \\\n",
    "    --model_name_or_path \"bigcode/starcoder2-7b\" \\\n",
    "    --lora_r 32 \\\n",
    "    --lora_alpha 64 \\\n",
    "    --lora_dropout 0.0 \\\n",
    "    --lora_target_modules \"c_proj,c_attn,q_attn,c_fc,c_proj\" \\\n",
    "    --use_nested_quant \\\n",
    "    --bnb_4bit_compute_dtype \"bfloat16\" \\\n",
    "    --use_flash_attn \\\n",
    "    --use_peft_lora \\\n",
    "    --use_4bit_quantization \\\n",
    "    --dataset_name \"smangrul/hug_stack\" \\\n",
    "    --dataset_text_field \"text\" \\\n",
    "    --max_seq_length 1024 \\\n",
    "    --fim_rate 0.5 \\\n",
    "    --fim_spm_rate 0.5 \\\n",
    "    --splits \"train\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --bf16 \\\n",
    "    --learning_rate 5e-4 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --max_steps 1000 \\\n",
    "    --warmup_steps 30 \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --evaluation_strategy \"steps\" \\\n",
    "    --eval_steps 50 \\\n",
    "    --save_steps 50 \\\n",
    "    --logging_steps 25 \\\n",
    "    --output_dir \"peft-lora-starcoder2-7b-personal-copilot-dual-3090-local\" \\\n",
    "    --resume_from_checkpoint \"peft-lora-starcoder2-7b-personal-copilot-dual-3090-local/checkpoint-450\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorboard\n",
    "\n",
    "```shell\n",
    "cd personal_copilot/training/peft-lora-starcoder2-7b-personal-copilot-dual-3090-local\n",
    "tensorboard --logdir=runs --bind_all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
